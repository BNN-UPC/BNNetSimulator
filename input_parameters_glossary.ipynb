{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation Parameters Glossary\n",
    "**THIS IS A GLOSSARY MEANT TO BE A REFERENCE, THE CODE CELLS ARE NOT MEANT TO BE EXECUTED**\n",
    "\n",
    "To build the dataset, we'll be working with three types of files that make up each sample:\n",
    "\n",
    "- **Graph topology**: This file represents a graph topology, including the nodes and edges that forms it as well as characterstics of each.\n",
    "- **Routing file**: This file shows the paths that traffic can take between each node within the graph topology.\n",
    "- **Traffic matrix (TM)**: This file represents the flows of traffic through a given network. It describe the traffic moving from one node to another.\n",
    "\n",
    "Each sample in the dataset is identified by a unique combination of these three files. This means that we can generate multiple samples from the same graph topology by pairing it with different traffic matrices, for example.\n",
    "\n",
    "In the following sections, we'll show you how to generate these files, and how their properties can be altered to create different variations of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate, for instance, a complete graph\n",
    "G = nx.complete_graph(10)\n",
    "\n",
    "# Set the number of ToS that the input traffic of the network can use. If it is not defined, the simulator sets it to 1.\n",
    "G.graph[\"levelsToS\"] = 3\n",
    "\n",
    "# Assign bandwidth to each edge of the graph. Its value is considered in bps.\n",
    "for (n0,n1) in G.edges():\n",
    "    G[n0][n1][\"bandwidth\"] = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in our network simulation is defined by two key characteristics:\n",
    "\n",
    "- **Scheduling policy**: The way in which packets are processed at each output port is determined by the state of the queues and the chosen scheduling policy. We consider the following four policies:\n",
    "    - *First In First Out (FIFO)*: all packets are placed in a single queue and served in the order they arrived, regardless of their type of service (ToS).\n",
    "    - *Strict Priority (SP)*: one queue is designated for each priority level, and packets in higher priority queues are served first.\n",
    "    - *Weighted Fair Queueing (WFQ)*: each queue is assigned a weight according to the configuration. The sum of all weights must equal 100. The policy selects a queue to serve based on its weight and the data rate of that queue, ensuring fairness among all queues.\n",
    "    - *Deficit Round Robin  (DRR)*: similar to WFQ, each queue is assigned a weight according to the configuration. The sum of all weights must equal 100. The policy cycles through the queues, dedicating time to each queue proportional to its weight.\n",
    "- **Buffer size**: the amount of storage space available at each output port for packets that are waiting to be processed. When a packet arrives and the outgoing queue is full, it will be dropped. The buffer size is measured in bits, with a minimum value of 8000 bits.\n",
    "\n",
    "It's important to remember that you will have to define these characteristics for all nodes in the topology. The scheduling policy of a node is stored in the attribute schedulingPolicy as a string.\n",
    "\n",
    "Here's some examples of nodes with the scheduling policy and buffer size defined:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a FIFO policy\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"FIFO\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to simulating network traffic, it's important to be able to control how packets with different types of service (ToS) are handled within the network. With the scheduling policies SP, WFQ, and DRR, we have an additional level of control through the tosToQoSqueue attribute.\n",
    "\n",
    "This attribute allows us to specify to which queues packets with different ToS should be placed in. For example, if we set the attribute to \"0;1,2\", we are telling the simulator to create two queues. Traffic with ToS 0 will be assigned to the first queue, and traffic with ToS 1 and 2 will be assigned to the second queue.\n",
    "\n",
    "If the tosToQoSqueue attribute is not set, the simulator will use a default behavior: it will create one queue for each ToS defined in the levelsToS attribute, and assign one ToS to each queue.\n",
    "\n",
    "Here's an example of a node with the tosToQoSqueue attribute defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a SP policy with two queues.\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"SP\"\n",
    "    G.nodes[node][\"tosToQoSqueue\"] = \"0;1,2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the scheduling policies of WFQ and DRR, we have an additional level of control over how packets are processed through the use of \"weights\" assigned to each queue. This is where the attribute schedulingWeights comes into play.\n",
    "\n",
    "To use this attribute, we will feed it a string containing the weights for each queue, separated by commas. For example, if we have 3 queues and we want to assign weights of 45, 30 and 25 to them respectively, the attribute will be set as \"45,30,25\".\n",
    "\n",
    "It is important to note that the sum of all weights must equal 100, otherwise the simulation will not work as expected.\n",
    "\n",
    "Here's an example of a node with the schedulingWeights attribute defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a WFQ policy with three queues\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"WFQ\"\n",
    "    G.nodes[node][\"tosToQoSqueue\"] = \"0;1;2\"\n",
    "    G.nodes[node][\"schedulingWeights\"] = \"45, 30, 25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a DRR policy with three queues\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"DRR\"\n",
    "    G.nodes[node][\"tosToQoSqueue\"] = \"0;1;2\"\n",
    "    G.nodes[node][\"schedulingWeights\"] = \"45, 30, 25\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the buffer size in our network simulation, we only need to modify the attribute bufferSizes and include the desired size of the buffer in bits. It's important to keep in mind that the buffer size should be greater than 8000 bits.\n",
    "\n",
    "Here's an example of a node with the bufferSizes attribute defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to each node a queue size of 32000 bits\n",
    "for node in G:\n",
    "    G.nodes[node][\"bufferSizes\"] = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we save the topology\n",
    "graph_file = \"graph.txt\"\n",
    "nx.write_gml(G,graph_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing\n",
    "The routing information for our network simulation is expressed in a text file, where each line represents a path through the network as a sequence of nodes. There are two types of routing that can be used: destination-based and source-destination-based routing.\n",
    "\n",
    "Destination-based routing is where packets are forwarded to the next hop based solely on their destination address. In contrast, source-destination-based routing takes into account both the source and destination addresses when forwarding packets.\n",
    "\n",
    "It's important to note that both types of routing should not contain loops. Loops can cause packets to circulate indefinitely, leading to network congestion and decreased performance.\n",
    "\n",
    "Here's an example of a routing file using destination-based routing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance, we can use networkx to calculate the shortest path routing for each src-dst pair.\n",
    "with open(\"routing.txt\",\"w\") as r_fd:\n",
    "    lPaths = nx.shortest_path(G)\n",
    "    for src in G:\n",
    "        for dst in G:\n",
    "            if src == dst:\n",
    "                continue\n",
    "            path =  ','.join(str(x) for x in lPaths[src][dst])\n",
    "            r_fd.write(path+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Matrix\n",
    "The final step in generating our network simulation is to create the traffic matrix (TM) file. This file contains information on the different traffic flows that will be present in the network. Each line in the file describes one flow, and the parameters are separated by commas. Here's a breakdown of the parameters:\n",
    "\n",
    "- **source and destination**: These parameters indicate the source and destination nodes for the given flow. \n",
    "\n",
    "- **avg_bw**: This parameter indicates the average bandwidth, in bps, to be generated for this flow. It's minimum value is 10 bps\n",
    "\n",
    "- **time_distribution**: This parameter indicates how often packets should be generated over time. We support three time distributions, as well as a generic distribution described using a Python script :\n",
    "  - Poisson(```time_distribution```=1): Generates packets according to a Poisson process. No extra parameters required.\n",
    "  - CBR(```time_distribution```=1): Generates packets at a constant bit rate. No extra parameters required.\n",
    "  - ON-OFF(```time_distribution```=2): Alternates between active and inactive periods. Additional parameters include the length of the activity and inactivity periods (```on_time``` and ```off_time``` respectively). Each period's duration follows an exponential distribution with an average duration of on_time or off_time seconds.\n",
    "  - EXT_PYTHON(```time_distribution```=3):Utilizes an external Python distribution. Requires at least the name of the Python class used to generate packet times, with additional parameters separated by commas. All parameters must be of type double. See the 'Generic Distribution' section for more details.\"\n",
    "\n",
    "- **pkt_dist**: This parameter notes the distribution type used to generate the packets. Two distribution is supported.\n",
    "  - Generic(```size_distribution```=0): Describe a set of packets size and and their relative frequency within the flow (**pkt_size_n** and **prob_n**). At least one packet size must be declared, but we can define up to 8 different sizes. The packet size should be a value between 50 and 2000 bits, while the sum of all the prob_n values should equal 1.\n",
    "  - EXT_PYTHON(```size_distribution```=1):Utilizes an external Python distribution to generate the packet sizes. Requires at least the name of the Python class used to generate packet times, with additional parameters separated by commas. All parameters must be of type double. See the 'Generic Distribution' section for more details.\n",
    "\n",
    "\n",
    "- **tos**: This parameter indicates the ToS assigned to the packets generated for this flow. When defining the tos to be used, select consecutive values starting from 0. For instance if you want to use 3 different ToS, select 0, 1 and 2.\n",
    "\n",
    "At the end, the resulting line should look something like this:\n",
    "\n",
    "```source, destination, avg_bw, time_distribution, [on_time, off_time,] pkt_dist, pkt_size_1, prob_1, [pkt_size_2, prob_2, [pkt_size_3, prob_3, [pkt_size_4, prob_4, [pkt_size_5, prob_5,]]]] tos```\n",
    "\n",
    "*Note:* It's possible to define more than one flow between two nodes, although this functionality is not fully tested and it's up to the user to use it. However, keep in mind that as the simulator provides performance metrics aggregated per path and for each flow, the size of the dataset can increase easily.\n",
    "\n",
    "By generating the traffic matrix file, you can control the different types of traffic that will be present in the network, leading to more accurate and realistic network traffic simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: this code will generate flows between all nodes in the graph, such as:\n",
    "- The average bandwidth is randomized between 10 and 10000 bps\n",
    "- An ON-OFF time distribution is used, with an average on_time of 5 s and an average off_time of 10 s\n",
    "- Packets can have two possible sizes, 300 and 1700 bits, both equally probable\n",
    "- The ToS for all flows is 0 (high priority)\n",
    "\"\"\"\n",
    "with open(\"traffic.txt\",\"w\") as tm_fd:\n",
    "    for src in G:\n",
    "        for dst in G:\n",
    "            avg_bw = random.randint(10,10000)\n",
    "            time_dist = 2\n",
    "            on_time = 5\n",
    "            off_time = 10\n",
    "            pkt_size_1 = 300\n",
    "            prob_1 = 0.5\n",
    "            pkt_size_2 = 1700\n",
    "            prob_2 = 0.5\n",
    "            tos = 0\n",
    "            traffic_line = \"{},{},{},{},{},{},0,{},{},{},{},{}\".format(\n",
    "                src,dst,avg_bw,time_dist,on_time,off_time,pkt_size_1,\n",
    "                prob_1,pkt_size_2,prob_2,tos)\n",
    "            tm_fd.write(traffic_line+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic python script generator\n",
    "\n",
    "BNNetSimulator offers the capability to utilize an external Python script for generating the time and size distribution of packets. This class should include a method named ```next()```, which is invoked by BNNetSimulator. When the external Python script is employed for defining the time distribution, the next() method returns the wait time, measured in nanoseconds, before generating a new packet (known as the Inter Packet Gap). Conversely, when the script is used for determining the size distribution, this method returns the size of the next packet to be generated in bits.\n",
    "\n",
    "Additionally, another method that this class should implement is ```get_average()```, which provides the average Inter Packet Gap and the average packet size, respectively.\n",
    "\n",
    "The _init__ function of the class depend on if it is used to generate a time distribution or a size distribution:\n",
    "\n",
    "- Time distribution: ```def __init__ (self, src_id, dst_id, flow_id, equivalent_lambda_bits, param_1,..., param_n, avg_pkt_size)```\n",
    "- Size distribution: ```def __init__ (self, src_id, dst_id, flow_id, param_1,..., param_m)```\n",
    "\n",
    "The list of params (param_1,..,param_n) are the additional parameters described when defining the traffic matrix. These parameters are expected to be of type double. The class method ```num_stream_parameters``` should return the count of these additional parameters.\n",
    "\n",
    "Here is an example of a class that would be used to generate packets whose size would follow a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class sd_uniform:\n",
    "\n",
    "    file_obj = {}\n",
    "    \n",
    "    def __init__ (self, src_id,dst_id,flow_id,min_pkt_size,max_pkt_size):\n",
    "        self.min_pkt_size = min_pkt_size\n",
    "        self.max_pkt_size = max_pkt_size\n",
    "        self.avg_pkt_size = (self.max_pkt_size - self.min_pkt_size)/2 + self.min_pkt_size;\n",
    "      \n",
    "    \n",
    "    # Return the number of parameters required by this module\n",
    "    @classmethod\n",
    "    def num_stream_parameters(cls):\n",
    "        # min_pkt_size and max_pkt_size\n",
    "        return (2)     \n",
    "        \n",
    "        \n",
    "    def get_next(self):        \n",
    "        return (round(np.random.uniform(self.min_pkt_size,self.max_pkt_size)))\n",
    "    \n",
    "    def get_average(self):\n",
    "        return (self.avg_pkt_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process a dataset that relies on external Python scripts, it is necessary to modify the datanetAPI.py file. At line 550, the dictionary _external_param_dic is defined. To add support for an external Python class, insert a new key-value pair into the dictionary. The key should be a string representing the name of the new class, and the value should be a list. In this list, the first parameter should be the name you wish to assign to the distribution, followed by the names of the parameters used by this distribution.\n",
    "\n",
    "For instanc, to add support for the class sd_uniform: ```self._external_param_dic = {\"sd_uniform\":[\"Uniform\",\"MinPktSize\",\"MaxPktSize\"]}```.\n",
    "\n",
    "Then rading a sample that use this dsistribution would be:\n",
    "\n",
    "```\n",
    "print (s.get_traffic_matrix()[0,1][\"Flows\"][0][\"SizeDist\"])\n",
    "    SizeDist.EXTERNAL_PY_S\n",
    "print (s.get_traffic_matrix()[0,1][\"Flows\"][0][\"SizeDistParams\"])\n",
    "    {'AvgPktSize': 1000.0, 'Distribution': 'Uniform', 'MinPktSize': 300.0, 'MaxPktSize': 1700.0}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4fabe4be1dcb5b95007215d13ed47b80f9ccf78939eea74ae4a681230c3cbef"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
